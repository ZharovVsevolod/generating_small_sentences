{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка моделей и их генерации\n",
    "\n",
    "В этом ноутбуке представлено, как импортировать все необходимые инструменты для генерации текста с помощью различных моделей, а также использование специального класса `TextGenerator` для top-k и top-p генерации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортирование модулей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчка в блоке ниже `%cd ..` необходима, поскольку этот ноутбук находится в смежной директории по отношению к пакету gen_names. В случае использования окружения, построенного с помощью `poetry`, данная строка не будет необходима и её можно закомментировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Studio\\mamba\\generating_small_sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wsewo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from gen_names.models.shell import Model_Lightning_Shell\n",
    "from gen_names.data import CharTokenizer\n",
    "from gen_names.generators import TextGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_name(name:str) -> str:\n",
    "    \"\"\"Функция для красивого читаемого отображения имени, сгенерированного моделью\"\"\"\n",
    "    return name[1].upper() + name[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer()\n",
    "model = Model_Lightning_Shell.load_from_checkpoint(\"weights/mamba_true.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arcentine\n",
      "Abbett\n",
      "Abell\n",
      "Antoise\n",
      "Astine\n"
     ]
    }
   ],
   "source": [
    "gen = TextGenerator(model, tokenizer, banned_idx=[0, 1, 2, 30, 31])\n",
    "\n",
    "for _ in range(5):\n",
    "    name = gen.generate(phrase=\"Fa\", mode=\"top_n\", k=5, n=0.9, max_len=9, max_repeat=2)\n",
    "    print(hf_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jalyn\n",
      "Dencia\n",
      "Shakeri\n",
      "Danti\n",
      "Dalen\n"
     ]
    }
   ],
   "source": [
    "gen = TextGenerator(model, tokenizer, banned_idx=[0, 1, 2, 30, 31])\n",
    "\n",
    "for _ in range(5):\n",
    "    name = gen.generate(phrase=\"F\", mode=\"top_n\", n=0.9, max_len=9, max_repeat=1)\n",
    "    print(hf_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delynn\n",
      "Stacey\n",
      "Shatia\n",
      "Analynn\n",
      "Nicca\n"
     ]
    }
   ],
   "source": [
    "gen = TextGenerator(model, tokenizer, banned_idx=[0, 1, 2, 30, 31])\n",
    "\n",
    "for _ in range(5):\n",
    "    name = gen.generate(phrase=\"F\", mode=\"top_n\", n=0.9, max_len=9)\n",
    "    print(hf_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daythe\n",
      "Krissa\n",
      "Nikola\n",
      "Jolyn\n",
      "Deence\n"
     ]
    }
   ],
   "source": [
    "gen = TextGenerator(model, tokenizer, banned_idx=[0, 1, 2, 30, 31])\n",
    "\n",
    "for _ in range(5):\n",
    "    name = gen.generate(phrase=\"F\", mode=\"top_k\", k=5, max_len=9)\n",
    "    print(hf_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shalend\n"
     ]
    }
   ],
   "source": [
    "gen = TextGenerator(model, tokenizer, banned_idx=[0, 1, 2, 30, 31])\n",
    "\n",
    "for _ in range(1):\n",
    "    name = gen.generate(phrase=\"F\", mode=\"top_k\", k=3, max_len=9, max_repeat=1)\n",
    "    print(hf_name(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wsewo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CharTokenizer()\n",
    "model = Model_Lightning_Shell.load_from_checkpoint(\"weights/transformer.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wsewo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanial\n",
      "Aleran\n",
      "Ameleya\n",
      "Aricini\n",
      "Jorine\n"
     ]
    }
   ],
   "source": [
    "gen = TextGenerator(model, tokenizer, banned_idx=[0, 1, 2, 30, 31])\n",
    "\n",
    "for _ in range(5):\n",
    "    name = gen.generate(phrase=\"F\", mode=\"top_k\", k=3, max_len=9)\n",
    "    print(hf_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wsewo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learriaha\n",
      "Madenale\n",
      "Micarre\n",
      "Aminali\n",
      "Melleaney\n"
     ]
    }
   ],
   "source": [
    "gen = TextGenerator(model, tokenizer, banned_idx=[0, 1, 2, 30, 31])\n",
    "\n",
    "for _ in range(5):\n",
    "    name = gen.generate(phrase=\"F\", mode=\"top_k\", k=3, max_len=9, max_repeat=2)\n",
    "    print(hf_name(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer()\n",
    "model = Model_Lightning_Shell.load_from_checkpoint(\"weights/lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abenita\n",
      "Agna\n",
      "Aji\n",
      "An\n",
      "Anfo\n"
     ]
    }
   ],
   "source": [
    "gen = TextGenerator(model, tokenizer, banned_idx=[0, 1, 2, 30, 31])\n",
    "\n",
    "for _ in range(5):\n",
    "    name = gen.generate(phrase=\"Fa\", mode=\"top_n\", k=5, n=0.9, max_len=9, max_repeat=1)\n",
    "    print(hf_name(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
